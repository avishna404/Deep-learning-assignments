{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOY1ueM9dIjywnAiraiqIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avishna404/Deep-learning-assignments/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Implement MLP from scratch & replace the backpropagation algorithm with any of the latest optimization algorithms."
      ],
      "metadata": {
        "id": "PmrvUlGRpFjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.W1 = np.random.randn(self.input_size, self.hidden_size[0])\n",
        "        self.W2 = np.random.randn(self.hidden_size[0], self.hidden_size[1])\n",
        "        self.W3 = np.random.randn(self.hidden_size[1], self.output_size)\n"
      ],
      "metadata": {
        "id": "SUzPvOTJpIjM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "vKBlv4RvpScw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, X):\n",
        "    self.z1 = np.dot(X, self.W1)\n",
        "    self.a1 = sigmoid(self.z1)\n",
        "    self.z2 = np.dot(self.a1, self.W2)\n",
        "    self.a2 = sigmoid(self.z2)\n",
        "    self.z3 = np.dot(self.a2, self.W3)\n",
        "    self.y_hat = sigmoid(self.z3)\n",
        "    return self.y_hat"
      ],
      "metadata": {
        "id": "GFL3g3lkpZ65"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(self, X, y):\n",
        "    y_hat = self.forward(X)\n",
        "    mse = np.mean((y - y_hat) ** 2)\n",
        "    return mse"
      ],
      "metadata": {
        "id": "DclcfMAJpdKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PSO:\n",
        "    def __init__(self, num_particles, max_iter, inertia_weight, cognitive_weight, social_weight):\n",
        "        self.num_particles = num_particles\n",
        "        self.max_iter = max_iter\n",
        "        self.inertia_weight = inertia_weight\n",
        "        self.cognitive_weight = cognitive_weight\n",
        "        self.social_weight = social_weight\n",
        "        self.gbest_fitness = float('inf')\n",
        "        self.gbest_position = None\n",
        "\n",
        "    def optimize(self, cost_function, bounds):\n",
        "        self.swarm_position = np.random.uniform(bounds[0], bounds[1], size=(self.num_particles, len(bounds)))\n",
        "        self.swarm_velocity = np.zeros_like(self.swarm_position)\n",
        "        self.pbest_position = self.swarm_position.copy()\n",
        "        self.pbest_fitness = np.zeros(self.num_particles)\n",
        "        self.gbest_fitness = float('inf')\n",
        "        self.gbest_position = None\n",
        "\n",
        "        for i in range(self.num_particles):\n",
        "            fitness = cost_function(self.swarm_position[i])\n",
        "            self.pbest_fitness[i] = fitness\n",
        "            if fitness < self.gbest_fitness:\n",
        "                self.gbest_fitness = fitness\n",
        "                self.gbest_position = self.swarm_position[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            for j in range(self.num_particles):\n",
        "                # Update velocity\n",
        "                r1 = np.random.rand(len(bounds))\n",
        "                r2 = np.random.rand(len(bounds))\n",
        "                cognitive_velocity = self.cognitive_weight * r1 * (self.pbest_position[j] - self.swarm_position[j])\n",
        "                social_velocity = self.social_weight * r2 * (self.gbest_position - self.swarm_position[j])\n",
        "                self.swarm_velocity[j] = self.inertia_weight * self.swarm_velocity[j] + cognitive_velocity + social_velocity\n",
        "\n",
        "                # Update position\n",
        "                self.swarm_position[j] = self.swarm_position[j] + self.swarm_velocity[j]\n",
        "\n",
        "                # Enforce bounds\n",
        "                self.swarm_position[j] = np.clip(self.swarm_position[j], bounds[0], bounds[1])\n",
        "\n",
        "                # Update pbest and gbest\n",
        "                fitness = cost_function(self.swarm_position[j])\n",
        "                if fitness < self.pbest_fitness[j]:\n",
        "                    self.pbest_fitness[j] = fitness\n",
        "                    self.pbest_position[j] = self.swarm_position[j]\n",
        "                    if fitness < self.gbest_fitness:\n",
        "                        self.gbest_fitness = fitness\n",
        "                        self.gbest_position = self.swarm_position[j]\n",
        "\n",
        "        return self.gbest_position\n"
      ],
      "metadata": {
        "id": "ZccnHU8dpli6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Cu0vVLoiprqv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the PSO-optimized MLP and solve for the weights and biases\n",
        "#from pso import PSO\n",
        "#from mlp import MLP\n",
        "\n",
        "pso = PSO(num_particles=20, problem_dim=32, max_iterations=100, error_tolerance=1e-4)\n",
        "pso.solve(X_train, y_train)\n",
        "mlp = pso.mlp\n",
        "\n",
        "# Test the MLP on the test data\n",
        "predicted = np.round(mlp.feedforward(X_test))\n",
        "accuracy = np.sum(predicted == y_test) / len(y_test)\n",
        "\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "     "
      ],
      "metadata": {
        "id": "W5EUisDqp2q8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}